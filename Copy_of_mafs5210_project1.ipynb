{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoleMa1220/RL-Project1/blob/main/Copy_of_mafs5210_project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78BjyscQzlaF",
        "outputId": "10fc2b4a-8d8a-4113-a6bb-1fa37ec1159b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy.stats as st\n",
        "import statsmodels.api as sm\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rlqIkXAClAC",
        "outputId": "b7a8ed35-3e5f-49d7-9e85-dc6f748cbd1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rPFD3ptNCt-o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "9ae19402-3a0b-4444-bfd4-09e96b759cd7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-310ee630342a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mturnoverRate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/MAFS5210_Group Project/turnoverRate.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mturnoverRate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(turnoverRate.index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mturnoverRate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturnoverRate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtemp_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mturnoverRate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mturnoverRate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/MAFS5210_Group Project/turnoverRate.csv'"
          ]
        }
      ],
      "source": [
        "turnoverRate = pd.read_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/turnoverRate.csv\",index_col=0)\n",
        "turnoverRate.sort_index(ascending=True,inplace = True)\n",
        "# print(turnoverRate.index)\n",
        "turnoverRate.index = pd.to_datetime(turnoverRate.index)\n",
        "temp_ind = pd.date_range(start=turnoverRate.index[0], end=turnoverRate.index[-1], freq='M')\n",
        "# !ls \"/content/drive/My Drive/MAFS5210_Group Project\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_time_len = (turnoverRate.index[-1] - turnoverRate.index[0]).days-504\n",
        "print(total_time_len,type(total_time_len))"
      ],
      "metadata": {
        "id": "Npz7Fd0ZJ2ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_giKhTPrR8Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrrqMUIOEfDc"
      },
      "outputs": [],
      "source": [
        "\n",
        "turn_1m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "turn_3m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "turn_6m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "std_turn_1m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "std_turn_3m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "std_turn_6m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "std_turn_2y = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "turn_2y = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "bias_turn_1m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "bias_turn_3m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "bias_turn_6m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "bias_std_turn_1m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "bias_std_turn_3m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "bias_std_turn_6m = pd.DataFrame(index = temp_ind, columns = turnoverRate.columns)\n",
        "\n",
        "for i in range(24, len(temp_ind)):\n",
        "  index_turn = temp_ind[i]\n",
        "\n",
        "  turn_1m.loc[index_turn,] = turnoverRate.loc[temp_ind[i-1]:temp_ind[i],].mean(0).tolist()\n",
        "  std_turn_1m.loc[index_turn,] = turnoverRate.loc[temp_ind[i-1]:temp_ind[i],].std(0).tolist()\n",
        "\n",
        "  turn_3m.loc[index_turn,] = turnoverRate.loc[temp_ind[i-3]:temp_ind[i],].mean(0).tolist()\n",
        "  std_turn_3m.loc[index_turn,] = turnoverRate.loc[temp_ind[i-3]:temp_ind[i],].std(0).tolist()\n",
        "\n",
        "  turn_6m.loc[index_turn,] = turnoverRate.loc[temp_ind[i-6]:temp_ind[i],].mean(0).tolist()\n",
        "  std_turn_6m.loc[index_turn,] = turnoverRate.loc[temp_ind[i-6]:temp_ind[i],].std(0).tolist()\n",
        "\n",
        "  turn_2y.loc[index_turn,] = turnoverRate.loc[temp_ind[i-24]:temp_ind[i],].mean(0).tolist()\n",
        "  std_turn_2y.loc[index_turn,] = turnoverRate.loc[temp_ind[i-24]:temp_ind[i],].mean(0).tolist()\n",
        "\n",
        "  bias_turn_1m.loc[index_turn,] = turn_1m.loc[index_turn,]/turn_2y.loc[index_turn,] - 1\n",
        "  bias_turn_3m.loc[index_turn,] = turn_3m.loc[index_turn,]/turn_2y.loc[index_turn,] - 1\n",
        "  bias_turn_6m.loc[index_turn, ]= turn_6m.loc[index_turn,]/turn_2y.loc[index_turn,] - 1\n",
        "  bias_std_turn_1m.loc[index_turn,] = std_turn_1m.loc[index_turn,]/std_turn_2y.loc[index_turn,] - 1\n",
        "  bias_std_turn_3m.loc[index_turn,] = std_turn_3m.loc[index_turn,]/std_turn_2y.loc[index_turn,] - 1\n",
        "  bias_std_turn_6m.loc[index_turn,] = std_turn_6m.loc[index_turn,]/std_turn_2y.loc[index_turn,] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCydn7xsQZJd"
      },
      "outputs": [],
      "source": [
        "data={}\n",
        "\n",
        "data['bias_std_turn_3m'] = bias_std_turn_3m.dropna(how= 'all')\n",
        "data['bias_std_turn_1m'] = bias_std_turn_1m.dropna(how= 'all')\n",
        "data['bias_std_turn_6m'] = bias_std_turn_6m.dropna(how= 'all')\n",
        "data['turn_1m'] = turn_1m.dropna(how= 'all')\n",
        "data['std_turn_1m'] = std_turn_1m.dropna(how= 'all')\n",
        "data['turn_3m'] = turn_3m.dropna(how= 'all')\n",
        "data['std_turn_3m'] = std_turn_3m.dropna(how= 'all')\n",
        "data['turn_6m'] = turn_6m.dropna(how= 'all')\n",
        "data['std_turn_6m'] = std_turn_6m.dropna(how= 'all')\n",
        "data['bias_turn_1m'] = bias_turn_1m.dropna(how= 'all')\n",
        "data['bias_turn_3m'] = bias_turn_3m.dropna(how= 'all')\n",
        "data['bias_turn_6m'] = bias_turn_6m.dropna(how= 'all')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['bias_turn_6m']"
      ],
      "metadata": {
        "id": "SynfYgmrlc9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgUtQfNLrk0R"
      },
      "outputs": [],
      "source": [
        "# for key in data.keys():\n",
        "#   print(len(data[key]))\n",
        "# data[varibles[i]].astype(float).corrwith(data[varibles[j]].astype(float),axis=1,method='pearson')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEAJmKDyQ1Zd"
      },
      "outputs": [],
      "source": [
        "## 各因子间相关性\n",
        "corr ={}\n",
        "\n",
        "varibles = ['turn_1m','turn_3m','turn_6m','bias_turn_1m','bias_turn_3m','bias_turn_6m','std_turn_1m','std_turn_3m','std_turn_6m','bias_std_turn_1m','bias_std_turn_3m','bias_std_turn_6m']\n",
        "\n",
        "# for i in range(len(varibles)):\n",
        "#   for j in range(i+1,len(varibles)):\n",
        "#  = data[varibles[i]].astype(float).corrwith(data[varibles[j]].astype(float),axis=1,method='pearson')\n",
        "    # for t in data[varibles[i]].index:\n",
        "    #   print(len(data[varibles[i]].loc[t,:].dropna()),len(data[varibles[j]].loc[t,:].dropna()))\n",
        "    #   # temp = np.corrcoef(data[varibles[i]].loc[t,:].dropna().tolist(),data[varibles[j]].loc[t,:].dropna().tolist())\n",
        "    #   temp1 = data[varibles[i]].loc[t,].astype(float).corr(data[varibles[j]].loc[t,].astype(float))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kiToS8phiZI"
      },
      "outputs": [],
      "source": [
        "# Cab = {}\n",
        "Std_df = pd.DataFrame(index =varibles,columns = varibles)\n",
        "Mean_df = pd.DataFrame(index =varibles,columns = varibles)\n",
        "Cab_df = pd.DataFrame(index =varibles,columns = varibles)\n",
        "for i in range(len(varibles)):\n",
        "  for j in range(i+1,len(varibles)):\n",
        "    tmp = data[varibles[i]].astype(float).corrwith(data[varibles[j]].astype(float),axis=1,method='pearson')\n",
        "    Std_df.loc[varibles[i],varibles[j]] = tmp.iloc[-36:].std()\n",
        "    Std_df.loc[varibles[j],varibles[i]] = tmp.iloc[-36:].std()\n",
        "    Mean_df.loc[varibles[i],varibles[j]] = tmp.iloc[-36:].mean()\n",
        "    Mean_df.loc[varibles[j],varibles[i]] = tmp.iloc[-36:].mean()\n",
        "    tmp_cab= tmp.iloc[-36:].mean()/tmp.iloc[-36:].std()\n",
        "    Cab_df.loc[varibles[j],varibles[i]] = tmp_cab\n",
        "    Cab_df.loc[varibles[i],varibles[j]] = tmp_cab\n",
        "    # print(Cab['corr{}_{}'.format(varibles[i],varibles[j])])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "各换手率因子间相关强度（近 36 个月）"
      ],
      "metadata": {
        "id": "h23oHwl_I3DM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHH4ixSehmbv"
      },
      "outputs": [],
      "source": [
        "Cab_df\n",
        "Cab_df.to_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/cab_df.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "各换手率因子间月度相关系数序列均值"
      ],
      "metadata": {
        "id": "v_ujH7mwJAr5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KABsIsLpFZG"
      },
      "outputs": [],
      "source": [
        "Mean_df\n",
        "Mean_df.to_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/Mean_df.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "各换手率因子间月度相关系数序列标准差"
      ],
      "metadata": {
        "id": "szodVHKzJC5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Std_df\n",
        "Std_df.to_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/Std_df.csv\")"
      ],
      "metadata": {
        "id": "q3rXdOCfJGer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "单因子回归检测"
      ],
      "metadata": {
        "id": "SgzkTCgZOM_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hs300 = pd.read_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/hs300.csv\",index_col=0)\n",
        "for i in range(len(hs300.columns)):\n",
        "  hs300.iloc[:,i] = hs300.iloc[:,i].apply(str).str.zfill(6)"
      ],
      "metadata": {
        "id": "soSJWbihKijm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data['bias_std_turn_3m']\n",
        "data_modified = {}\n",
        "# for col in data['bias_std_turn_3m'].columns:\n",
        "for fatcor in varibles:\n",
        "  data_modified[fatcor] = pd.DataFrame(index = data[fatcor].index, columns = data[fatcor].columns)\n",
        "  for i in range(len(data[fatcor].index)):\n",
        "    stock_tmp = hs300.iloc[:,i]\n",
        "    data_sect = data[fatcor].iloc[i,:][stock_tmp]\n",
        "    Dm = data_sect.median()\n",
        "    Dm1 = data_sect.sub(Dm).abs().median()\n",
        "    upper = Dm+5*Dm1\n",
        "    lower = Dm-5*Dm1\n",
        "    data_sect[data_sect>upper] = upper\n",
        "    data_sect[data_sect<lower] = lower\n",
        "    mean = data_sect.mean()\n",
        "    std = data_sect.std()\n",
        "    data_sect = (data_sect-mean)/std\n",
        "    data_sect.fillna(0,inplace= True)\n",
        "    data_modified[fatcor].iloc[i,:][stock_tmp] = data_sect\n",
        "  data_modified[fatcor].fillna(0,inplace = True)"
      ],
      "metadata": {
        "id": "j9hkeWqWO8-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hs300_index = pd.read_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/hs300_index.csv\",index_col=0)\n",
        "hs300_index.index = hs300_index.loc[:,'tradeDate']\n",
        "hs300_index = hs300_index.loc[:,'CHGPct']\n",
        "hs300_index.sort_index(ascending=True,inplace = True)\n",
        "hs300_index.index = pd.to_datetime(hs300_index.index)\n",
        "# # temp_ind = pd.date_range(start=closePrice.index[0], end=closePrice.index[-1], freq='M')\n",
        "hs300_index = hs300_index.groupby([lambda x:x.year, lambda x: x.month]).sum().iloc[:-1]\n",
        "hs300_index.index = temp_ind\n",
        "hs300_index = hs300_index.loc[data['bias_std_turn_6m'].index,]"
      ],
      "metadata": {
        "id": "igmz70pX7YE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closePrice = pd.read_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/ClosePrice.csv\",index_col=0)\n",
        "closePrice.sort_index(ascending=True,inplace = True)\n",
        "closePrice.index = pd.to_datetime(closePrice.index)\n",
        "# temp_ind = pd.date_range(start=closePrice.index[0], end=closePrice.index[-1], freq='M')\n",
        "closePrice = closePrice.groupby([lambda x:x.year, lambda x: x.month]).last('1D').iloc[:-1]\n",
        "closePrice.index = temp_ind"
      ],
      "metadata": {
        "id": "tWaNh71SPrdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "returnRate = closePrice.sub(closePrice.shift(1)).div(closePrice.shift(1))\n",
        "returnRate = returnRate.shift(-1)\n",
        "returnRate_modified = pd.DataFrame(index = returnRate.index, columns = returnRate.columns)\n",
        "\n",
        "for i in range(len(returnRate)):\n",
        "  stock_tmp = hs300.iloc[:,i]\n",
        "  data_sect = returnRate.iloc[i,:][stock_tmp]\n",
        "  returnRate_modified.iloc[i,:][stock_tmp] = data_sect\n",
        "# returnRate_modified.fillna(0,inplace = True)\n",
        "returnRate_modified = returnRate_modified.loc[data_modified['bias_std_turn_6m'].index,]\n",
        "returnRate.fillna(0,inplace = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "_8ctlXBtWM1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# closePrice.loc[returnRate_modified.index]\n",
        "closePrice.pct_change()"
      ],
      "metadata": {
        "id": "VicMJXIQ7l3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "returnRate_modified"
      ],
      "metadata": {
        "id": "yEg9wbwzoKU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marketValue = pd.read_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/marketValue.csv\",index_col=0)\n",
        "marketValue.sort_index(ascending=True,inplace = True)\n",
        "marketValue.index = pd.to_datetime(marketValue.index)\n",
        "# temp_ind = pd.date_range(start=closePrice.index[0], end=closePrice.index[-1], freq='M')\n",
        "marketValue = marketValue.groupby([lambda x:x.year, lambda x: x.month]).mean().iloc[:-1]\n",
        "marketValue.index = temp_ind\n",
        "marketValue_modified = pd.DataFrame(index = marketValue.index, columns = marketValue.columns)\n",
        "\n",
        "for i in range(len(marketValue)):\n",
        "  stock_tmp = hs300.iloc[:,i]\n",
        "  data_sect = marketValue.iloc[i,:][stock_tmp]\n",
        "  # print(data_sect)\n",
        "  marketValue_modified.iloc[i,:][stock_tmp] = data_sect\n",
        "  # print(marketValue_modified.iloc[i,:][stock_tmp] ==data_sect)\n",
        "marketValue_modified = marketValue_modified.loc[data_modified['bias_std_turn_6m'].index,]\n",
        "marketValue.fillna(0,inplace = True)"
      ],
      "metadata": {
        "id": "tXSTitVGp-gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model = sm.WLS(np.array(returnRate,dtype=float), np.array(data_modified['bias_std_turn_3m'],dtype=float), weights=np.sqrt(np.array(marketValue,dtype=float))).fit()\n",
        "# print(model.params[])\n",
        "t_value = {}\n",
        "for i in range(len(varibles)):\n",
        "  t_value[varibles[i]] = pd.Series(index = returnRate_modified.columns)\n",
        "  print(varibles[i])\n",
        "  for stock in returnRate_modified.columns:\n",
        "    # print(stock)\n",
        "    time_len = marketValue_modified.loc[:,stock].dropna().index\n",
        "    if not time_len.empty:\n",
        "      # x = sm.add_constant(np.array(data_modified[varibles[i]].loc[time_len,stock]))\n",
        "      model = sm.WLS(np.array(returnRate_modified.loc[time_len,stock]), np.array(data_modified[varibles[i]].loc[time_len,stock])+1e-9,\\\n",
        "          weights=np.sqrt(marketValue_modified.loc[time_len,stock].astype(float))).fit()\n",
        "      # print(model.tvalues[0])\n",
        "      # break\n",
        "      t_value[varibles[i]].loc[stock] = model.tvalues[0]\n",
        "      # print(t_value[varibles[i]].loc[stock])\n",
        "   "
      ],
      "metadata": {
        "id": "5bFcvmrbm3n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[varibles[i]]"
      ],
      "metadata": {
        "id": "WDa_R0VWRpcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(varibles)):\n",
        "  print(\"{} t value abs average\".format(varibles[i]),round(t_value[varibles[i]].abs().mean(),6))\n",
        "  ## 因为没有行业分类数据 所以。。。。"
      ],
      "metadata": {
        "id": "YZgkHZxdnUMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "因子IC IR"
      ],
      "metadata": {
        "id": "54PzGqZkThvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# returnRate.loc[data_modified[varibles[i]].index[j],stock_tmp]\n",
        "# data_modified[varibles[i]].iloc[:,j].astype(float).corr(returnRate.loc[data_modified[varibles[i]].index[j],stock_tmp].astype(float),method='pearson')\n",
        "# np.std(IC.dropna())\n",
        "# np.std(IC_new)\n",
        "len(IC_new)"
      ],
      "metadata": {
        "id": "PReszBVnXYNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "res = pd.DataFrame(index =varibles,columns = ['IC std','IC mean','IR','IC>0 ratio'])\n",
        "\n",
        "for i in range(len(varibles)):\n",
        "  IC = []\n",
        "  for j in range(len(data_modified[varibles[i]])):\n",
        "    stock_tmp = hs300.iloc[:,j]    \n",
        "    tmp = data_modified[varibles[i]].loc[data_modified[varibles[i]].index[j],stock_tmp].astype(float).corr(returnRate.loc[data_modified[varibles[i]].index[j],stock_tmp].astype(float),method='pearson')\n",
        "    IC.append(tmp)\n",
        "  new_list=[]\n",
        "  for elem in IC:\n",
        "    if not np.isnan(elem):\n",
        "      new_list.append(elem)\n",
        "  res.loc[varibles[i],'IC std'] = np.std(new_list)\n",
        "  res.loc[varibles[i],'IC mean'] = np.mean(new_list)\n",
        "  res.loc[varibles[i],'IR'] = res.loc[varibles[i],'IC mean']/res.loc[varibles[i],'IC std']\n",
        "  res.loc[varibles[i],'IC>0 ratio'] = np.sum(i>0 for i in new_list)/len(new_list) \n",
        "res\n",
        "\n",
        "res.to_csv(\"/content/drive/MyDrive/MAFS5210_Group Project/regIC.csv\")\n",
        "    # print(Cab['corr{}_{}'.format(varibles[i],varibles[j])])"
      ],
      "metadata": {
        "id": "94H_xMkwTkTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "分层"
      ],
      "metadata": {
        "id": "UGw-hpj8mdcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for var in range(len(varibles)):\n",
        "  group = pd.DataFrame(index =data[varibles[var]].index,columns =['group 1','group 2','group 3','group 4','group 5'] )\n",
        "  print(\"{} starts\".format(varibles[var]))\n",
        "  for i in range(len(data[varibles[var]])):\n",
        "    stock_tmp = hs300.iloc[:,i]\n",
        "    factor = data[varibles[var]].iloc[i,].loc[stock_tmp].sort_values()\n",
        "    factor = factor[factor != 0.0]\n",
        "    num_group = int(len(factor)/5)\n",
        "    # if (factor == 0.0).any() :\n",
        "    #   print((factor != 0.0).sum())\n",
        "    for j in range(5):\n",
        "      tmp = factor.iloc[j*num_group:(j+1)*num_group].index\n",
        "      group.iloc[i,j] = returnRate.loc[data[varibles[var]].index[i],tmp].mean()\n",
        "\n",
        "  plt.figure(1)\n",
        "  plt.plot((group.loc[:,'group 1']+1).cumprod(),label='group 1')\n",
        "  plt.plot((group.loc[:,'group 2']+1).cumprod(),label='group 2')\n",
        "  plt.plot((group.loc[:,'group 3']+1).cumprod(),label='group 3')\n",
        "  plt.plot((group.loc[:,'group 4']+1).cumprod(),label='group 4')\n",
        "  plt.plot((group.loc[:,'group 5']+1).cumprod(),label='group 5')\n",
        "  plt.plot((hs300_index+1).cumprod(),label='HS300 index')\n",
        "  plt.title(\"{} factor backtest net value\".format(varibles[var]))\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  index_cum =(hs300_index+1).cumprod()\n",
        "  plt.figure(2)\n",
        "  plt.plot((group.loc[:,'group 1']+1).cumprod().div(index_cum),label='group 1')\n",
        "  plt.plot((group.loc[:,'group 2']+1).cumprod().div(index_cum),label='group 2')\n",
        "  plt.plot((group.loc[:,'group 3']+1).cumprod().div(index_cum),label='group 3')\n",
        "  plt.plot((group.loc[:,'group 4']+1).cumprod().div(index_cum),label='group 4')\n",
        "  plt.plot((group.loc[:,'group 5']+1).cumprod().div(index_cum),label='group 5')\n",
        "  plt.title(\"{} factor backtest net value divided by HS300 index\".format(varibles[var]))\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  duokong = group.loc[:,'group 5'].sub(group.loc[:,'group 1'])\n",
        "\n",
        "  fig, ax1 = plt.subplots(figsize=(10,6))\n",
        "  ax1.bar(duokong.index,duokong.values,width=0.5)\n",
        "  ax1.set_xticklabels(duokong.index)\n",
        "  ax1.set_xlabel('Date')\n",
        "  ax1.set_ylabel('retrurn rate*100%', color='b')\n",
        "  ax2 = ax1.twinx()\n",
        "  ax2.plot((duokong+1).cumprod(), 'r-')\n",
        "  ax2.set_ylabel('accumulate retrurn rate', color='r')\n",
        "  plt.title(\"{} long-short portfolio monthly return and cumulative return\".format(varibles[var]))\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  res_df = pd.DataFrame(index = ['group 1','group 2','group 3','group 4','group 5','long-short portfolio'],\\\n",
        "                      columns =['Annualized return','Annualized volatility','Sharpe ratio',\\\n",
        "                            'excess annualized return','excess annualized volatility','Information ratio','monthly win rate'])\n",
        "  for i in group.columns:\n",
        "    res_df.loc[i,'Annualized volatility'] = group.loc[:,i].std()*12**0.5\n",
        "    res_df.loc[i,'Annualized return'] = (group.loc[:,i]+1).cumprod()[-1]/total_time_len*365\n",
        "    res_df.loc[i,'Sharpe ratio'] = res_df.loc[i,'Annualized return']/res_df.loc[i,'Annualized volatility'] \n",
        "    res_df.loc[i,'excess annualized volatility'] = (group.loc[:,i]-hs300_index).std()*12**0.5\n",
        "    res_df.loc[i,'excess annualized return'] = (group.loc[:,i]+1-hs300_index).cumprod()[-1]/total_time_len*365\n",
        "    res_df.loc[i,'Information ratio'] = res_df.loc[i,'excess annualized return']/res_df.loc[i,'excess annualized volatility'] \n",
        "    res_df.loc[i,'monthly win rate'] = (group.loc[:,i]>0).sum()/len(group.loc[:,i])\n",
        "\n",
        "    \n",
        "  res_df.loc['long-short portfolio','Annualized volatility'] = duokong.std()*12**0.5\n",
        "  res_df.loc['long-short portfolio','Annualized return'] = (duokong+1).cumprod()[-1]/total_time_len*365\n",
        "  res_df.loc['long-short portfolio','Sharpe ratio'] = res_df.loc['long-short portfolio','Annualized return']/res_df.loc['long-short portfolio','Annualized volatility'] \n",
        "  res_df.loc['long-short portfolio','excess annualized volatility'] = (duokong-hs300_index).std()*12**0.5\n",
        "  res_df.loc['long-short portfolio','excess annualized return'] = (duokong+1-hs300_index).cumprod()[-1]/total_time_len*365\n",
        "  res_df.loc['long-short portfolio','Information ratio'] = res_df.loc['long-short portfolio','excess annualized return']/res_df.loc['long-short portfolio','excess annualized volatility'] \n",
        "  res_df.loc['long-short portfolio','monthly win rate'] = (duokong>0).sum()/len(duokong)\n",
        "\n",
        "  print(res_df)\n",
        "  print('finish!')"
      ],
      "metadata": {
        "id": "Zj8DXu1sqiRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (group.loc[:,i]+1).cumprod()[-1]/4"
      ],
      "metadata": {
        "id": "4ARxwq6JrU7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "igNHdrrPrW4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yVpaWucPtFXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# duokong = group.loc[:,'group 5'].sub(group.loc[:,'group 1'])\n",
        "\n",
        "# fig, ax1 = plt.subplots(figsize=(10,6))\n",
        "# ax1.bar(duokong.index,duokong.values,width=0.5)\n",
        "# ax1.set_xticklabels(duokong.index)\n",
        "# ax1.set_xlabel('Date')\n",
        "# ax1.set_ylabel('retrurn rate*100%', color='b')\n",
        "# ax2 = ax1.twinx()\n",
        "# ax2.plot((duokong+1).cumprod(), 'r-')\n",
        "# ax2.set_ylabel('accumulate retrurn rate', color='r')\n",
        "\n",
        "\n",
        "# # fig, ax = plt.subplots()\n",
        "# # ax2 = ax.twinx()\n",
        "# # ax.bar(duokong.index, duokong, color=(190/255,190/255,190/255,0.7), )\n",
        "# # ax2.plot(duokong.index, (duokong+1).cumprod(), color='green', label='Hold')\n",
        "# # ax.set_xticklabels(duokong.index)\n",
        "# # ax.legend(loc='best')"
      ],
      "metadata": {
        "id": "95gbBhWfBDYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RS4inDPrShTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bw8bKxSHAV_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X7ztMb25CI76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gX7SPcDKJWW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1SuCquM8LE94"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of mafs5210 project1",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}